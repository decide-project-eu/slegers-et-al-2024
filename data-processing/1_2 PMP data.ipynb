{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15c992b8-64b6-492d-926b-8ee701807e97",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "spark.sparkContext.hadoopConfiguration.set(\n",
    "  \"<directory>",\n",
    "  \"<key>"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8d2cbc7-684e-4acc-abe6-2152e68a1a34",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, StringType, StructType, StructField, DoubleType, TimestampType, FloatType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea994460-1dfe-40a5-ba0d-7ddf64af48d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "PMP_extra_koppels = spark. \\\n",
    "  read. \\\n",
    "  option(\"header\", \"true\"). \\\n",
    "  option(\"delimiter\", \",\"). \\\n",
    "  csv(\"wasbs://decide@decide.blob.core.windows.net/poultry/nl/data_avinet/PMP_extra_koppels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f42c02d-1dbc-44db-887d-49a95349d61e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "PMP_extra_koppels_2021 = spark. \\\n",
    "  read. \\\n",
    "  option(\"header\", \"true\"). \\\n",
    "  option(\"delimiter\", \",\"). \\\n",
    "  csv(\"wasbs://decide@decide.blob.core.windows.net/poultry/nl/data_avinet/PMP_extra_koppels_2021.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7eac0703-9dcf-4b26-bbba-30c04d9c8dd9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70cb889a-ad07-4e4b-b890-f93fe57fceae",
     "showTitle": true,
     "title": "UDF to correct pen names"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def pen_correction(text):\n",
    "    dict = {\n",
    "    \" \" : \"\",\n",
    "    \"-\" : \"\"} \n",
    "    \n",
    "    #if value is Null, do nothing\n",
    "    if text is not None:\n",
    "        # Create a regular expression  from the dictionary keys\n",
    "        regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape, dict.keys())))\n",
    "        # For each match, look-up corresponding value in dictionary\n",
    "        text = regex.sub(lambda mo: dict[mo.string[mo.start():mo.end()]], text) \n",
    "        text = text.lower()\n",
    "    return text\n",
    "\n",
    "pen_correction_udf = udf(pen_correction, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "548a7e33-c221-4477-bef3-f0e2ddeee822",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "PMP = PMP_extra_koppels \\\n",
    "    .union(PMP_extra_koppels_2021) \\\n",
    "    .withColumnRenamed('Rijlabels', 'VetId') \\\n",
    "    .withColumnRenamed('Koppel', 'Round') \\\n",
    "    .withColumnRenamed('Geboortedatum', 'HatchDate') \\\n",
    "    .withColumnRenamed('KplId', 'FlockIdentification') \\\n",
    "    .withColumnRenamed('Weglaaddatum I en R', 'RemovalDate') \\\n",
    "    .withColumnRenamed('UBN', 'FarmIdentification') \\\n",
    "    .withColumnRenamed('Registratienummer', 'PoultryFarmIdentification') \\\n",
    "    .withColumnRenamed('Groeicurve Soort', 'GrowthCurve') \\\n",
    "    .withColumnRenamed('Is Uitgeladen', 'Thinned') \\\n",
    "    .withColumn('House', pen_correction_udf(F.col('Stal'))) \\\n",
    "    .withColumn('HatchDate',\n",
    "                F.to_timestamp(F.col('HatchDate'), \"dd-MM-yy\")) \\\n",
    "    .withColumn('RemovalDate',\n",
    "                F.to_timestamp(F.col('RemovalDate'), \"dd-MM-yy\")) \\\n",
    "    .filter(F.col('HatchDate') >= \"2013-01-01 00:00:00\") \\\n",
    "    .withColumn('FlockIdentification', F.col('FlockIdentification').cast('integer')) \\\n",
    "    .withColumn('Round', F.col('Round').cast('integer')) \\\n",
    "    .withColumn('FarmIdentification', F.col('FarmIdentification').cast('integer')) \\\n",
    "    .withColumn('VetId', F.col('VetId').cast('integer')) \\\n",
    "    .drop('Stal') \\\n",
    "    .distinct()\n",
    "\n",
    "# 'Round' is a flock identification but not per house. 'FlockIdentification' is. So 'Round' could be used to identify flocks (in a house) that are on a farm at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "407f4464-8644-41c2-aade-05db7dc39a31",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dfFlock = spark.read.parquet(\"wasbs://decide@decide.blob.core.windows.net/poultry/nl/data_avinet/dfFlock.parquet\") \\\n",
    "    .withColumn('BirthDate',\n",
    "                F.to_timestamp(F.col('BirthDate'), \"yy-MM-dd\")) \\\n",
    "    .filter(F.col('BirthDate') >= \"2013-01-01 00:00:00\") \\\n",
    "    .withColumnRenamed('BirthDate', 'HatchDate') \\\n",
    "    .withColumn('House', pen_correction_udf(F.col('PenNumber'))) \\\n",
    "    .drop('PenNumber')\n",
    "\n",
    "# 'KPLID' = FlockIdentification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5065ecf4-df11-44c2-addb-d24ab25e0411",
     "showTitle": true,
     "title": "Join dfFlock with extra PMP data"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-1338157218712346>:7\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# 50 flocks are double in dfFlocks because two houses belong to one flock id.\u001B[39;00m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# so join with PMP on at flockId and House.\u001B[39;00m\n",
       "\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# drop columns in PMP that are double.\u001B[39;00m\n",
       "\u001B[1;32m      5\u001B[0m dfPMPFlocks \u001B[38;5;241m=\u001B[39m PMP \\\n",
       "\u001B[1;32m      6\u001B[0m     \u001B[38;5;241m.\u001B[39mdrop(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFarmIdentification\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPoultryFarmIdentification\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHatchDate\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRemovalDate\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGrowthCurve\u001B[39m\u001B[38;5;124m'\u001B[39m) \\\n",
       "\u001B[0;32m----> 7\u001B[0m     \u001B[38;5;241m.\u001B[39mjoin(\u001B[43mdfFlock\u001B[49m, on \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFlockIdentification\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHouse\u001B[39m\u001B[38;5;124m'\u001B[39m], how \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minner\u001B[39m\u001B[38;5;124m'\u001B[39m) \\\n",
       "\u001B[1;32m      8\u001B[0m     \u001B[38;5;241m.\u001B[39mdistinct()\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'dfFlock' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-1338157218712346>:7\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# 50 flocks are double in dfFlocks because two houses belong to one flock id.\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# so join with PMP on at flockId and House.\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# drop columns in PMP that are double.\u001B[39;00m\n\u001B[1;32m      5\u001B[0m dfPMPFlocks \u001B[38;5;241m=\u001B[39m PMP \\\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;241m.\u001B[39mdrop(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFarmIdentification\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPoultryFarmIdentification\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHatchDate\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRemovalDate\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGrowthCurve\u001B[39m\u001B[38;5;124m'\u001B[39m) \\\n\u001B[0;32m----> 7\u001B[0m     \u001B[38;5;241m.\u001B[39mjoin(\u001B[43mdfFlock\u001B[49m, on \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFlockIdentification\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHouse\u001B[39m\u001B[38;5;124m'\u001B[39m], how \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minner\u001B[39m\u001B[38;5;124m'\u001B[39m) \\\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;241m.\u001B[39mdistinct()\n\n\u001B[0;31mNameError\u001B[0m: name 'dfFlock' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'dfFlock' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 50 flocks are double in dfFlocks because two houses belong to one flock id.\n",
    "# so join with PMP on at flockId and House.\n",
    "# drop columns in PMP that are double.\n",
    "# filter on double flocks due to VetID: see notebook 'Data Slaughter'\n",
    "\n",
    "dfPMPFlocks = PMP \\\n",
    "    .drop('FarmIdentification', 'PoultryFarmIdentification', 'HatchDate', 'RemovalDate', 'GrowthCurve') \\\n",
    "    .join(dfFlock, on = ['FlockIdentification', 'House'], how = 'inner') \\\n",
    "    .distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66ce3be9-1d39-4cb8-a0fd-d91c748bd976",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dfPMPFlocks.write \\\n",
    "    .format(\"parquet\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(\"wasbs://decide@decide.blob.core.windows.net/poultry/nl/data_avinet/dfPMPFlocks.parquet\")\n",
    "\n",
    "# first version: 19/9/23\n",
    "# edit: \n",
    "# 22/9/23 corrected VetId\n",
    "# 25/9/23 added 2021"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1_2 PMP data",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
